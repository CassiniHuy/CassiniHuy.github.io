<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>论文笔记：CAM、Grad-CAM、Grad-CAM++和Smooth Grad-CAM++ | 渭城岸的博客</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="苟日新，日日新，又日新。">
<meta property="og:type" content="article">
<meta property="og:title" content="论文笔记：CAM、Grad-CAM、Grad-CAM++和Smooth Grad-CAM++">
<meta property="og:url" content="http://weichengan.com/2020/11/30/paper_notes/cam_notes/index.html">
<meta property="og:site_name" content="渭城岸的博客">
<meta property="og:description" content="苟日新，日日新，又日新。">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2020-11-30T15:22:42.000Z">
<meta property="article:modified_time" content="2023-02-17T06:55:48.110Z">
<meta property="article:author" content="cassiniwei@outlook.com">
<meta property="article:tag" content="神经网络">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="可解释性">
<meta property="article:tag" content="可视化">
<meta name="twitter:card" content="summary">
  
  
    <link rel="icon" href="/images/favicon.ico">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  

  

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 5.4.2"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">渭城岸的博客</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-github-link" class="nav-icon" href="https://github.com/CassiniHuy" title="Github" target="_blank"></a>
        
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://weichengan.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-paper_notes/cam_notes" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    
<a href="/2020/11/30/paper_notes/cam_notes/" class="article-date">
  <time class="dt-published" datetime="2020-11-30T15:22:42.000Z" itemprop="datePublished">2020-11-30</time>
</a>


    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      论文笔记：CAM、Grad-CAM、Grad-CAM++和Smooth Grad-CAM++
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
		
		<div id="toc" class="toc-article">
			<h2 class="toc-title"><span>Contents</span></h2>
		
			<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Learning-Deep-Features-for-Discriminative-Localization"><span class="toc-number">1.</span> <span class="toc-text">Learning Deep Features for Discriminative Localization</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Grad-CAM-Visual-Explanations-from-Deep-Networks-via-Gradient-based-Localization"><span class="toc-number">2.</span> <span class="toc-text">Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Grad-CAM-Generalized-Gradient-based-Visual-Explanations-for-Deep-Convolutional-Networks"><span class="toc-number">3.</span> <span class="toc-text">Grad-CAM++: Generalized Gradient-based Visual Explanations for Deep Convolutional Networks</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Smooth-Grad-CAM-An-Enhanced-Inference-Level-Visualization-Technique-for-Deep-Convolutional-Neural-Network-Models"><span class="toc-number">4.</span> <span class="toc-text">Smooth Grad-CAM++: An Enhanced Inference Level Visualization Technique for Deep Convolutional Neural Network Models</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93"><span class="toc-number">5.</span> <span class="toc-text">笔记总结</span></a></li></ol>
		
		</div>
		
        <p>由CAM引出的基于梯度的类别激活图可视化方法：Grad-CAM、Grad-CAM++和Smooth Grad-CAM++，这里只抽取核心，不包括实验。</p>
<span id="more"></span>
<hr>
<h2 id="Learning-Deep-Features-for-Discriminative-Localization"><a href="#Learning-Deep-Features-for-Discriminative-Localization" class="headerlink" title="Learning Deep Features for Discriminative Localization"></a>Learning Deep Features for Discriminative Localization</h2><p>CAM，提出使用最后一层卷积来可视化网络的预测过程。</p>
<p>最后一层必须是Global Average Pooling，直接使用最后一层卷积后的full connect权重作为不同特征值的线性和的权重。</p>
<p>下面所讨论都是指最后一层卷积。</p>
<p>用$F^k$表示第k个卷积核（特征图），$f^k(x,y)$为其激活值，则c类的score（softmax前）按如下计算（global sum）：</p>
<script type="math/tex; mode=display">S_c=\sum_k w^k_c \sum_{x,y}f^k(x,y)=\sum_{x,y} \sum_k w^k_c f^k(x,y)</script><p>自然的，对于不同$x,y$，其对最后score做的贡献，即CAM可计算为：</p>
<script type="math/tex; mode=display">M_c(x,y)=\sum_k w^k_c f^k(x,y)</script><p>最后再上采样到与input image同尺寸即可。</p>
<p>对于如果采用Global Max Pooling的差别，作者说得很明白，可以想见，使用GMP，CAM上面只会出现最后一层卷积核个数个点：</p>
<blockquote>
<p>Given the prior work [16] on using GMP for weakly supervised object localization, we believe it is important to highlight the intuitive difference between GAP and GMP. We believe that GAP loss encourages the network to identify the extent of the object as compared to GMP which encourages it to identify just one discriminative part. This is because, when doing the average of a map, the value can be maximized by finding all discriminative parts of an object as all low activations reduce the output of the particular map. On the other hand, for GMP, low scores for all image regions except the most discriminative one do not impact the score as you just perform a max.</p>
</blockquote>
<hr>
<h2 id="Grad-CAM-Visual-Explanations-from-Deep-Networks-via-Gradient-based-Localization"><a href="#Grad-CAM-Visual-Explanations-from-Deep-Networks-via-Gradient-based-Localization" class="headerlink" title="Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization"></a>Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization</h2><p>CAM对于网络结构有要求，不采用GAP方法不能使用；且只能可视化最后一层的卷积。</p>
<p>作者提出基于梯度的方法Grad-CAM化解了对于网络结构的上述限制：</p>
<p>在CAM中，不同特征图特征线性和的权重是使用训练得到的GAP；在Grad-CAM中，使用特征图梯度的GAP值来衡量不同特征图结合的重要性，即：</p>
<script type="math/tex; mode=display">w^k_c=\sum_{x,y}\frac{\partial S_c}{\partial f^k(x,y)}</script><p>于是Grad-CAM有：</p>
<script type="math/tex; mode=display">M_c(x,y)=ReLU(\sum_k w^k_c f^k(x,y))</script><p>梯度的正负表示对score增大的正反影响及其程度，最后保留正值，即仅可视化对score的正面影响；值得注意的是，若在权重计算过程中，将梯度取负值，则可视化结果是对于类别c预测起负面作用。</p>
<p>下证明Grad-CAM是CAM的一个推广，即使用GAP层时，两者等价：</p>
<p>仅需证明权重相等</p>
<p>使用GAP层时，使用CAM的权重计算为网络参数值，记为$\hat{w}^k_c$;</p>
<p>Grad-CAM的权重计算为</p>
<p>$w^k<em>c=\sum</em>{x,y}\frac{\partial S<em>c}{\partial f^k(x,y)}=\sum</em>{x,y}\frac{1}{Z}\hat{w}^k_c=\hat{w}^k_c$;</p>
<p>其中$Z=\sum_{x,y}1$</p>
<hr>
<h2 id="Grad-CAM-Generalized-Gradient-based-Visual-Explanations-for-Deep-Convolutional-Networks"><a href="#Grad-CAM-Generalized-Gradient-based-Visual-Explanations-for-Deep-Convolutional-Networks" class="headerlink" title="Grad-CAM++: Generalized Gradient-based Visual Explanations for Deep Convolutional Networks"></a>Grad-CAM++: Generalized Gradient-based Visual Explanations for Deep Convolutional Networks</h2><p>Grad-CAM严格推广了CAM，在CAM中，由于所有网络都是使用的GAP，所以计算权重时对特征图梯度GAP与之等价；但是对于其他如full Connected网络而言，同一个特征图，不同坐标下权重不同，GAP没有考虑这种差异。</p>
<p>Grad-CAM++的可视化方法如下，$Y_c$是类别c的预测分数，有：</p>
<ol>
<li><p>预测目标类别的score，假设由不同特征图GAP后，再线性加权得到：</p>
<script type="math/tex; mode=display">Y_c=\sum_k w^k_c\sum_{x,y}f^k(x,y)</script></li>
<li><p>线性加权的权重$w^k_c$计算如下，对于某个特征图，由特征图内的激活值线性加权而来：</p>
<script type="math/tex; mode=display">w^k_c=\sum_{x,y}\alpha^k_c(x,y)\cdot ReLU(\frac{\partial S_c}{\partial f^k(x,y)})</script></li>
<li><p>则有最终目标类别的score计算如下：</p>
<script type="math/tex; mode=display">Y_c=\sum_k \sum_{x,y}\alpha^k_c(x,y)\cdot ReLU(\frac{\partial S_c}{\partial f^k(x,y)})\sum_{i,j}f^k(i,j) \tag{*}</script></li>
</ol>
<p>在作者的假设下，有表达式(*)，其中$Y_c$不针对特定的计算方式，例如，softmax之前之后都可作为假设，或者其他网络结构计算得到的某个值作为表达式(*)的$Y_c$。在不同的假设前提下，得到的类别激活图的意义也发生变化。</p>
<p>和CAM和Grad-CAM一样，输入图像的Grad-CAM++由不同通道的激活值线性加权求和得到：</p>
<script type="math/tex; mode=display">M_c(x,y)=\sum_k w^k_c f^k(x,y)=\sum_k w^k_c\cdot f^k(x,y) \tag{**}</script><p>$\alpha^k_c(x,y)$的具体求法是：通过(*)式的两边对$f^k(x,y)$求偏导两次，得到二阶偏导表达式，然后解出$\alpha^k_c(x,y)$（请参见原论文）。</p>
<hr>
<h2 id="Smooth-Grad-CAM-An-Enhanced-Inference-Level-Visualization-Technique-for-Deep-Convolutional-Neural-Network-Models"><a href="#Smooth-Grad-CAM-An-Enhanced-Inference-Level-Visualization-Technique-for-Deep-Convolutional-Neural-Network-Models" class="headerlink" title="Smooth Grad-CAM++: An Enhanced Inference Level Visualization Technique for Deep Convolutional Neural Network Models"></a>Smooth Grad-CAM++: An Enhanced Inference Level Visualization Technique for Deep Convolutional Neural Network Models</h2><p>卷积核在提取特征的过程中，使用连续的值提取特征，在输入图像被关注物体的背景中，也存在一些特征会激活神经元，求梯度时会表现为“噪声”。可以参考<a href="http://weichengan.com/2020/11/30/notes/Deep_Inside_Convolutional_Networks-Notes/" title="论文笔记：Deep Inside Convolutional Networks: Visualising Image Classification">上一篇笔记</a>中的情况。</p>
<p> 作者提出使用SMOOTHGRAD的方法来抑制噪声，强化特征，即输入图像$I$的CAM为：</p>
<script type="math/tex; mode=display">M_c(I)=\frac{1}{n}\sum_1^n M_c(I+\mathcal{N}(0,\sigma^2))</script><p>其中添加的是高斯噪声，即式(**)的计算过程如下，$I$是输入的图像：</p>
<script type="math/tex; mode=display">M_c(x,y)=\sum_k w^k_c f^k(x,y)=\sum_k w^k_c\cdot \frac{1}{n}\sum^n_1(f^k_{x,y}|_{I+\mathcal{N}(0,\sigma^2)})</script><p>由于添加了噪声，所以更能够突出特征图在噪声中robust的部分，这部分被认为更重要；此方法可以用来比较图片不同位置对神经元的激活强度，所以可以进行choosing neurons的操作，在论文中为，针对某个卷积核，针对特征图某个(x,y)，可以对其生成可视化结果。可能的应用场景在debugging上。</p>
<hr>
<h2 id="笔记总结"><a href="#笔记总结" class="headerlink" title="笔记总结"></a>笔记总结</h2><p>上面四篇论文一脉相承，按论文的思路，SM Grad-CAM++理论上是效果最好的，因为从CAM到SM Grad-CAM++，是越来越推广的，除了某些细节外。</p>
<p>假设目标类别的score是由特征图线性加权得到，然后重点在于权重在各自的假设下的不同的求法。</p>

      
    </div>
    <footer class="article-footer">
	  
	  <!-- 百度分享 Start -->
	  <div class="bdsharebuttonbox"><a href="#" class="bds_more" data-cmd="more"></a><a href="#" class="bds_qzone" data-cmd="qzone" title="分享到QQ空间"></a><a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a><a href="#" class="bds_tqq" data-cmd="tqq" title="分享到腾讯微博"></a><a href="#" class="bds_renren" data-cmd="renren" title="分享到人人网"></a><a href="#" class="bds_weixin" data-cmd="weixin" title="分享到微信"></a></div>
	  <!-- 百度分享 End -->
    
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%8F%AF%E8%A7%86%E5%8C%96/" rel="tag">可视化</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/" rel="tag">可解释性</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag">深度学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="tag">神经网络</a></li></ul>

	  

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2020/12/01/reading_notes/captial_nd_surplus_value/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          《政治经济学概论》阅读笔记：资本和剩余价值
        
      </div>
    </a>
  
  
    <a href="/2020/11/30/paper_notes/Deep_Inside_Convolutional_Networks-Notes/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">论文笔记：Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps</div>
    </a>
  
</nav>

  
</article>



  <section id="comments" class="vcomment">

  </section>
</section>
        
          
  <div id="toc" class="toc-aside">
  <h2 class="toc-title">Contents</h2>
    
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Learning-Deep-Features-for-Discriminative-Localization"><span class="toc-number">1.</span> <span class="toc-text">Learning Deep Features for Discriminative Localization</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Grad-CAM-Visual-Explanations-from-Deep-Networks-via-Gradient-based-Localization"><span class="toc-number">2.</span> <span class="toc-text">Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Grad-CAM-Generalized-Gradient-based-Visual-Explanations-for-Deep-Convolutional-Networks"><span class="toc-number">3.</span> <span class="toc-text">Grad-CAM++: Generalized Gradient-based Visual Explanations for Deep Convolutional Networks</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Smooth-Grad-CAM-An-Enhanced-Inference-Level-Visualization-Technique-for-Deep-Convolutional-Neural-Network-Models"><span class="toc-number">4.</span> <span class="toc-text">Smooth Grad-CAM++: An Enhanced Inference Level Visualization Technique for Deep Convolutional Neural Network Models</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93"><span class="toc-number">5.</span> <span class="toc-text">笔记总结</span></a></li></ol>
    
  </div>

<aside id="sidebar">

  
    
<div class="widget-wrap">
  <h3 class="widget-title">ABOUT ME</h3>
  <ul class="widget about-me">
    
    <li><img class="author" title="About me" src="/images/coffee_onetwo.jpg" /></li>
    
    
    <li>Hi, LuYongjian! LYJNB!</li>
    
  </ul>
</div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E9%9A%8F%E7%AC%94/">随笔</a><span class="category-list-count">9</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/CTC/" style="font-size: 13px; color: #7dc3de">CTC</a> <a href="/tags/GAN/" style="font-size: 14.17px; color: #6dc1b9">GAN</a> <a href="/tags/PyTorch/" style="font-size: 13px; color: #7dc3de">PyTorch</a> <a href="/tags/RTX-4090/" style="font-size: 13px; color: #7dc3de">RTX 4090</a> <a href="/tags/ReLU/" style="font-size: 14.17px; color: #6dc1b9">ReLU</a> <a href="/tags/Text-to-Image/" style="font-size: 13px; color: #7dc3de">Text-to-Image</a> <a href="/tags/Windows%E7%BC%96%E7%A8%8B/" style="font-size: 13px; color: #7dc3de">Windows编程</a> <a href="/tags/copyright/" style="font-size: 13px; color: #7dc3de">copyright</a> <a href="/tags/nvidia/" style="font-size: 13px; color: #7dc3de">nvidia</a> <a href="/tags/tensorflow-1-15/" style="font-size: 13px; color: #7dc3de">tensorflow 1.15</a> <a href="/tags/viterbi%E7%AE%97%E6%B3%95/" style="font-size: 13px; color: #7dc3de">viterbi算法</a> <a href="/tags/%E4%B8%AD%E5%BF%83%E5%8C%96%E5%B7%AE%E5%88%86%E9%9A%90%E7%A7%81/" style="font-size: 13px; color: #7dc3de">中心化差分隐私</a> <a href="/tags/%E4%BA%8C%E5%80%BC%E5%8C%96/" style="font-size: 13px; color: #7dc3de">二值化</a> <a href="/tags/%E4%BB%A3%E7%A0%81%E6%B3%A8%E5%85%A5/" style="font-size: 13px; color: #7dc3de">代码注入</a> <a href="/tags/%E4%BD%8E%E9%80%9A%E6%BB%A4%E6%B3%A2/" style="font-size: 13px; color: #7dc3de">低通滤波</a> <a href="/tags/%E4%BD%8E%E9%80%9A%E6%BB%A4%E6%B3%A2%E5%99%A8/" style="font-size: 13px; color: #7dc3de">低通滤波器</a> <a href="/tags/%E5%86%85%E5%AD%98%E6%B3%84%E9%9C%B2/" style="font-size: 13px; color: #7dc3de">内存泄露</a> <a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%A6%E4%B9%A0/" style="font-size: 13px; color: #7dc3de">分布式学习</a> <a href="/tags/%E5%89%8D%E5%90%91%E7%AE%97%E6%B3%95/" style="font-size: 13px; color: #7dc3de">前向算法</a> <a href="/tags/%E5%8D%8F%E4%BD%9C%E5%AD%A6%E4%B9%A0/" style="font-size: 13px; color: #7dc3de">协作学习</a> <a href="/tags/%E5%8F%8C%E7%BA%BF%E6%80%A7%E6%8F%92%E5%80%BC/" style="font-size: 13px; color: #7dc3de">双线性插值</a> <a href="/tags/%E5%8F%AF%E8%A7%86%E5%8C%96/" style="font-size: 16.5px; color: #4dbc6f">可视化</a> <a href="/tags/%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/" style="font-size: 17.67px; color: #3db94a">可解释性</a> <a href="/tags/%E5%90%8E%E9%97%A8%E6%94%BB%E5%87%BB/" style="font-size: 13px; color: #7dc3de">后门攻击</a> <a href="/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/" style="font-size: 13px; color: #7dc3de">图像分割</a> <a href="/tags/%E5%9B%BE%E7%89%87%E8%AF%86%E5%88%AB/" style="font-size: 13px; color: #7dc3de">图片识别</a> <a href="/tags/%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB/" style="font-size: 16.5px; color: #4dbc6f">对抗攻击</a> <a href="/tags/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC/" style="font-size: 14.17px; color: #6dc1b9">对抗样本</a> <a href="/tags/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/" style="font-size: 13px; color: #7dc3de">对比学习</a> <a href="/tags/%E5%B7%AE%E5%88%86%E9%9A%90%E7%A7%81/" style="font-size: 13px; color: #7dc3de">差分隐私</a> <a href="/tags/%E6%94%BF%E6%B2%BB%E7%BB%8F%E6%B5%8E%E5%AD%A6%E6%A6%82%E8%AE%BA/" style="font-size: 13px; color: #7dc3de">政治经济学概论</a> <a href="/tags/%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/" style="font-size: 14.17px; color: #6dc1b9">数字信号处理</a> <a href="/tags/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/" style="font-size: 14.17px; color: #6dc1b9">数字图像处理</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E6%8A%95%E6%AF%92/" style="font-size: 13px; color: #7dc3de">数据投毒</a> <a href="/tags/%E6%9C%AC%E5%9C%B0%E5%8C%96%E5%B7%AE%E5%88%86%E9%9A%90%E7%A7%81/" style="font-size: 13px; color: #7dc3de">本地化差分隐私</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 14.17px; color: #6dc1b9">机器学习</a> <a href="/tags/%E6%A8%A1%E5%9E%8B%E9%B2%81%E6%A3%92%E6%80%A7/" style="font-size: 13px; color: #7dc3de">模型鲁棒性</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 20px; color: #1db400">深度学习</a> <a href="/tags/%E7%89%88%E6%9D%83%E4%BF%9D%E6%8A%A4/" style="font-size: 13px; color: #7dc3de">版权保护</a> <a href="/tags/%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/" style="font-size: 13px; color: #7dc3de">生成对抗网络</a> <a href="/tags/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/" style="font-size: 13px; color: #7dc3de">生成模型</a> <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" style="font-size: 18.83px; color: #2db725">神经网络</a> <a href="/tags/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 13px; color: #7dc3de">联邦学习</a> <a href="/tags/%E8%A7%86%E9%A2%91/" style="font-size: 13px; color: #7dc3de">视频</a> <a href="/tags/%E8%B7%A8%E6%A8%A1%E6%80%81/" style="font-size: 13px; color: #7dc3de">跨模态</a> <a href="/tags/%E8%BF%87%E6%8B%9F%E5%90%88/" style="font-size: 13px; color: #7dc3de">过拟合</a> <a href="/tags/%E9%87%8D%E9%87%87%E6%A0%B7/" style="font-size: 13px; color: #7dc3de">重采样</a> <a href="/tags/%E9%87%8D%E9%87%87%E6%A0%B7%E7%AE%97%E6%B3%95/" style="font-size: 13px; color: #7dc3de">重采样算法</a> <a href="/tags/%E9%98%88%E5%80%BC%E5%A4%84%E7%90%86/" style="font-size: 13px; color: #7dc3de">阈值处理</a> <a href="/tags/%E9%99%8D%E9%87%87%E6%A0%B7/" style="font-size: 13px; color: #7dc3de">降采样</a> <a href="/tags/%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4/" style="font-size: 15.33px; color: #5dbe94">隐私保护</a> <a href="/tags/%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB/" style="font-size: 13px; color: #7dc3de">隐马尔可夫</a> <a href="/tags/%E9%9F%B3%E9%A2%91%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB/" style="font-size: 14.17px; color: #6dc1b9">音频对抗攻击</a> <a href="/tags/%E9%9F%B3%E9%A2%91%E9%A2%84%E5%A4%84%E7%90%86/" style="font-size: 13px; color: #7dc3de">音频预处理</a> <a href="/tags/%E9%A2%91%E8%B0%B1%E6%B7%B7%E5%8F%A0/" style="font-size: 13px; color: #7dc3de">频谱混叠</a> <a href="/tags/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB/" style="font-size: 13px; color: #7dc3de">马尔可夫</a>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/02/">February 2023</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/01/">January 2023</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/10/">October 2022</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/03/">March 2022</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/12/">December 2021</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/11/">November 2021</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/09/">September 2021</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/06/">June 2021</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/05/">May 2021</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/03/">March 2021</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/01/">January 2021</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/12/">December 2020</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/11/">November 2020</a><span class="archive-list-count">3</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2023/02/17/suibi/image_lowpass_filtering/">Image Low-pass Filtering Algorithms Ideal/Butterworth/Gaussian (PyTorch Implementation) 图像低通滤波算法PyTorch实现</a>
          </li>
        
          <li>
            <a href="/2023/01/09/suibi/nv_tf1155_bug/">nvidia-tensorflow 1.15.5的signal模块的一个内存泄漏bug</a>
          </li>
        
          <li>
            <a href="/2022/10/18/paper_notes/cvpr20_video_backdoor/">CVPR2020 Clean-Label Backdoor Attacks on Video Recognition Models</a>
          </li>
        
          <li>
            <a href="/2022/03/31/suibi/code_inject/">代码注入：调用CreateProcess使explorer启动目标进程</a>
          </li>
        
          <li>
            <a href="/2021/12/16/paper_notes/xmcgan/">论文笔记：Cross-Modal Contrastive Learning for Text-to-Image Generation, CVPR 2021</a>
          </li>
        
      </ul>
    </div>
  </div>


  
    
<div class="widget-wrap">
  <h3 class="widget-title">Links</h3>
  <ul class="widget">
    
    <li><a href="https://qgrain.github.io/" target="_BLANK">Zhiyu&#39;s Blog</a></li>
    
    <li><a href="https://github.com/CassiniHuy" target="_BLANK">CassiniHuy&#39;s Github</a></li>
    
    <li><a href="https://www.marxists.org/chinese/marx/index.htm" target="_BLANK">中文马克思主义文库</a></li>
    
    <li><a href="https://www.zdic.net/" target="_BLANK">汉典</a></li>
    
  </ul>
</div>


  

</aside>

        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 cassiniwei@outlook.com<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> and Theme by <a href="https://github.com/howiefh/hexo-theme-landscape-f" target="_blank" title="Landscape-F">Landscape-F</a>
    
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<!-- 百度分享 start -->
<script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":["mshare","douban","bdysc","sqq","qq","hi","baidu","huaban","youdao","sdo","mail","xg","diandian","fx","copy","print"],"bdPic":"","bdStyle":"1","bdSize":"16"},"share":{},"image":{"viewList":["qzone","tsina","tqq","renren","weixin"],"viewText":"分享到","viewSize":"16"}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];</script>
<!-- 百度分享 end -->



<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>



<div class="bottom-btn">

	<a class="icon-gotop" href="javascript:void(0)" title="返回顶部"></a>
	
<script src="/js/gotop.js"></script>



	<a class="icon-toc-toggle" href="javascript:void(0)" title="文章目录"></a>
	
<script src="/js/toc_aside_toggle.js"></script>


</div>



<script src="/js/script.js"></script>









  
<script src="https://cdn.jsdelivr.net/npm/valine@1.3.10/dist/Valine.min.js"></script>

<script>
    var GUEST_INFO = ['nick','mail','link'];
    var guest_info = 'nick,mail,link'.split(',').filter(function(item){
        return GUEST_INFO.indexOf(item) > -1
    });
    var notify = 'true' == true;
    var verify = 'true' == true;
    new Valine({
        el: '.vcomment',
        notify: notify,
        verify: verify,
        appId: "sA5b5bSKVOumVxcKtX8NUqFk-gzGzoHsz",
        appKey: "glFUguQG84y2GTeKhQR0RNAX",
        placeholder: "Feel free to comment but new comment notification is disabled. Please contact me by cassiniwei@outlook.com if needed.",
        pageSize:'10',
        avatar:'mm',
        lang:''
    });
</script>


  </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>
