<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>论文笔记：Membership Inference Attacks Against Machine Learning Models, S&amp;P 2017 | 渭城岸的博客</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="苟日新，日日新，又日新。">
<meta property="og:type" content="article">
<meta property="og:title" content="论文笔记：Membership Inference Attacks Against Machine Learning Models, S&amp;P 2017">
<meta property="og:url" content="http://weichengan.com/2021/12/05/paper_notes/member_inference_attack/index.html">
<meta property="og:site_name" content="渭城岸的博客">
<meta property="og:description" content="苟日新，日日新，又日新。">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://weichengan.com/2021/12/05/paper_notes/member_inference_attack/Untitled.png">
<meta property="og:image" content="http://weichengan.com/2021/12/05/paper_notes/member_inference_attack/Untitled1.png">
<meta property="og:image" content="http://weichengan.com/2021/12/05/paper_notes/member_inference_attack/Untitled2.png">
<meta property="article:published_time" content="2021-12-05T12:38:46.000Z">
<meta property="article:modified_time" content="2023-02-17T06:55:48.124Z">
<meta property="article:author" content="cassiniwei@outlook.com">
<meta property="article:tag" content="隐私保护">
<meta property="article:tag" content="机器学习">
<meta property="article:tag" content="过拟合">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://weichengan.com/2021/12/05/paper_notes/member_inference_attack/Untitled.png">
  
  
    <link rel="icon" href="/images/favicon.ico">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  

  

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 5.4.2"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">渭城岸的博客</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-github-link" class="nav-icon" href="https://github.com/CassiniHuy" title="Github" target="_blank"></a>
        
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://weichengan.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-paper_notes/member_inference_attack" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    
<a href="/2021/12/05/paper_notes/member_inference_attack/" class="article-date">
  <time class="dt-published" datetime="2021-12-05T12:38:46.000Z" itemprop="datePublished">2021-12-05</time>
</a>


    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      论文笔记：Membership Inference Attacks Against Machine Learning Models, S&amp;P 2017
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
		
		<div id="toc" class="toc-article">
			<h2 class="toc-title"><span>Contents</span></h2>
		
			<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%95%E8%A8%80"><span class="toc-number">1.</span> <span class="toc-text">引言</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%97%AE%E9%A2%98%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">1.1.</span> <span class="toc-text">问题是什么？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AF%E8%BF%99%E4%B8%AA%E9%97%AE%E9%A2%98%EF%BC%9F"><span class="toc-number">1.2.</span> <span class="toc-text">为什么是这个问题？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%BA%E6%96%87%E7%9A%84Overview"><span class="toc-number">1.3.</span> <span class="toc-text">论文的Overview</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%B9%E6%B3%95"><span class="toc-number">2.</span> <span class="toc-text">方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%B9%E6%B3%95%E6%80%9D%E8%B7%AF"><span class="toc-number">2.1.</span> <span class="toc-text">方法思路</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E6%9D%A5%E6%BA%90"><span class="toc-number">2.2.</span> <span class="toc-text">数据集来源</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BD%B1%E5%AD%90%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%92%8C%E4%B8%AA%E6%95%B0"><span class="toc-number">2.3.</span> <span class="toc-text">影子模型的设计和个数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E6%94%BB%E5%87%BB%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.4.</span> <span class="toc-text">训练攻击模型</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E6%9E%9C"><span class="toc-number">3.</span> <span class="toc-text">结果</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%A8%E8%AE%BA"><span class="toc-number">4.</span> <span class="toc-text">讨论</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%87%E6%8B%9F%E5%90%88%E8%B6%8A%E4%B8%A5%E9%87%8D%EF%BC%8C%E6%94%BB%E5%87%BB%E6%95%88%E6%9E%9C%E8%B6%8A%E5%A5%BD"><span class="toc-number">4.1.</span> <span class="toc-text">过拟合越严重，攻击效果越好</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%98%B2%E5%BE%A1"><span class="toc-number">4.2.</span> <span class="toc-text">防御</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%84%E4%BB%B7"><span class="toc-number">5.</span> <span class="toc-text">评价</span></a></li></ol>
		
		</div>
		
        <p>原文发表在<a target="_blank" rel="noopener" href="http://www.ieee-security.org/TC/SP2017/papers/313.pdf">S&amp;P, 2017</a>；代码：<a target="_blank" rel="noopener" href="https://github.com/AdrienBenamira/membership_inference_attack">Github</a></p>
<span id="more"></span>
<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><h3 id="问题是什么？"><a href="#问题是什么？" class="headerlink" title="问题是什么？"></a>问题是什么？</h3><p>在文章中，主要讨论的是如何解决这样一个问题：判断一条数据是不是在目标模型的训练集中？</p>
<p>具体说：</p>
<ul>
<li>场景：现有一个模型$F:X\mapsto \hat{y}$，其中$X$是输入的数据（图片、病人的特征、用户的特征等等），假设是$C$个类别的分类问题，那么输出的向量$\hat{y}\in\mathbb{R}^C$，且$\hat{y}<em>i\in[0,1],\sum</em>{1}^C\hat{y}_i=1$，其实也就是softmax或者sigmoid的输出。</li>
<li>攻击者能力：可以以API的方式访问这个模型（目标模型作为黑盒存在），可以输入数据给模型，然后获得输出$\hat{y}$</li>
<li>攻击者目标：对于任意一条数据$(X,y)$（对于攻击者而言，其真实标签$y$是知道的），判断这条数据是不是在目标模型$F$的训练集中。</li>
</ul>
<h3 id="为什么是这个问题？"><a href="#为什么是这个问题？" class="headerlink" title="为什么是这个问题？"></a>为什么是这个问题？</h3><p>问题的实际意义在于，攻击者可以判断用户隐私是否被用于训练模型。<strong>注意，其只是判断一条数据是不是在训练集中，而不是去窃取这条数据。</strong>也就是说，攻击者是知道这条数据的，攻击者只是不知道这条数据是不是在训练集中。</p>
<p>这个攻击目标的实际意义如何，见仁见智了。</p>
<h3 id="论文的Overview"><a href="#论文的Overview" class="headerlink" title="论文的Overview"></a>论文的Overview</h3><p>论文思路：</p>
<ul>
<li>数据驱动，设法训练一个二分类模型来预测数据是不是在训练集中</li>
<li>也就是，想办法模拟目标模型的行为，生成很多很多$\hat{y}$，多到可以训练一个二分类模型来预测数据在不在训练集中</li>
</ul>
<p>论文结果：</p>
<ul>
<li>效果比较好（在过拟合的情况下）</li>
</ul>
<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>对于攻击者来说，只能获知目标模型的输出。好消息是，不仅仅是预测的类别结果，而是一个表示概率分布的预测向量。</p>
<p>所以，充分利用模型输出的类别的概率分布（也就是$\hat{y}$）的信息。</p>
<h3 id="方法思路"><a href="#方法思路" class="headerlink" title="方法思路"></a>方法思路</h3><p>方法如下：</p>
<p><img src="/2021/12/05/paper_notes/member_inference_attack/Untitled.png" alt="Untitled"></p>
<ul>
<li>想办法得到和目标模型的训练尽可能一样的数据集（分为训练集和测试集），然后训练一堆影子模型(Shadow Model)</li>
<li>影子模型：尽可能和目标模型一样，训练方法、参数也尽可能像</li>
<li>然后用这些影子模型，分别输入训练集和测试集，得到大量的$\hat{y}$，组成攻击模型的训练集</li>
<li>用这个训练集去训练一个攻击模型（二分类任务）</li>
</ul>
<p>具体而言，可以分为下面几个步骤：</p>
<h3 id="数据集来源"><a href="#数据集来源" class="headerlink" title="数据集来源"></a>数据集来源</h3><p>理想情况是攻击者可以获得和目标模型训练集完全重合的数据集。</p>
<p>此阶段攻击者目标：获取数据集${X_1,X_2,\cdots}$</p>
<p>实际上，在论文的实验中，其使用了四种来源的数据：</p>
<ol>
<li>Model-based synthesis：攻击者通过反复调用目标模型的API，来生成一些数据，好奇具体算法可以参考原论文。论文中，对于<a target="_blank" rel="noopener" href="https://kaggle.com/c/acquire-valued-shoppers-challenge/data">购物数据集</a>，作者合成了30k数据，每条数据156次调用。</li>
<li>Statistics-based synthesis：攻击者知道输入数据$X$的一些统计特征。例如如果$X$代表病人的特征，攻击者知道特征的边界值，某些离散特征可能有几种取值。</li>
<li>Noisy real data：攻击者知道目标模型的训练集，但是是有噪声的版本。作者通过将$X$的一定比例的特征随机化，来模拟这种情况。例如，训练集样本所含特征的10%被随机化。</li>
<li>作者直接使用了目标模型的数据集，但是和目标模型的训练集不相交。例如将CIFAR-100分为不相交的两部分，一部分给受害者用户，用来训练目标模型；然后另一部分给攻击者，攻击者用来训练影子模型然后训练攻击模型。</li>
</ol>
<p>最后一种情况，是作者论文中大部分篇幅实验的数据来源。</p>
<p>而1-3种情况，攻击者的能力逐渐增强，从只能通过API合成数据，到可以直接获得数据（有噪声的）。</p>
<p>个人认为，也就1-2来源在现实中比较实际。</p>
<h3 id="影子模型的设计和个数"><a href="#影子模型的设计和个数" class="headerlink" title="影子模型的设计和个数"></a>影子模型的设计和个数</h3><p>理想情况是攻击者可以使用和目标模型一样的算法、结构、训练参数等等。</p>
<p>实际上，作者设想了两种情况：</p>
<ul>
<li>攻击者已知目标模型的算法、结构</li>
<li>目标模型是在谷歌、亚马逊这些公司提供的云服务MLaaS上训练的；攻击者可以使用一样的MLaaS服务来训练影子模型。</li>
</ul>
<p>第二种情况比第一种实际一些，论文中也主要针对MLaaS上训练的目标模型。</p>
<p>作者根据不同的数据集，使用了从10到100不同数目的影子模型。对于CIFAR图片分类，作者用了100个影子模型。</p>
<p><img src="/2021/12/05/paper_notes/member_inference_attack/Untitled1.png" alt="Untitled"></p>
<h3 id="训练攻击模型"><a href="#训练攻击模型" class="headerlink" title="训练攻击模型"></a>训练攻击模型</h3><p>攻击者需要训练最终的攻击模型，流程如下：</p>
<ul>
<li>对于每个影子模型的训练：攻击者将得到的数据${X_1,X_2,\cdots}$分为训练集和测试集（对于不同影子模型，数据集可以相交）。</li>
<li>训练完成之后，分别将训练集和测试集输入影子模型，得到影子模型的预测向量$\hat{y}_{shadow}$。</li>
<li>测试集生成的预测向量，其标签就是out；训练集生成预测向量，其标签就是in。然后将这些数据（真实标签和影子模型的预测结果的组合，每一条数据都是$(y,\hat{y}_{shadow})$的样子，标签为in或者out）作为攻击模型的训练集。</li>
<li>所有影子模型最终会生成和${X_1,X_2,\cdots}$个数一样多的攻击模型的训练集</li>
<li>训练攻击模型</li>
</ul>
<p>攻击模型的结构由攻击者决定。论文中，作者简单使用一个全连接神经网络，甚至使用MLaaS服务来训练也行。</p>
<p>由上，最后得到一个执行二分类任务的攻击模型$f_{attack}:(y,\hat{y})\mapsto in/out$，输入数据$X$的真实标签、目标模型的预测向量，输出in或者out，代表其在不在目标模型训练集中。</p>
<h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><p>不详述，总之，效果挺好（目标模型过拟合了）。</p>
<p>作者用了很多图表来说明攻击效果如何好，详见论文。</p>
<p>这里就讨论一张表：</p>
<p><img src="/2021/12/05/paper_notes/member_inference_attack/Untitled2.png" alt="Untitled"></p>
<p>括号中代表epoch数，可以预料，越大，过拟合越严重。</p>
<p>而攻击精确度高的，都是过拟合严重（从training和testing的accuracy差别可以看出）的；如果过拟合不严重，攻击效果就不行。</p>
<h2 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h2><h3 id="过拟合越严重，攻击效果越好"><a href="#过拟合越严重，攻击效果越好" class="headerlink" title="过拟合越严重，攻击效果越好"></a>过拟合越严重，攻击效果越好</h3><p>论文作者强调，过拟合不是攻击效果好的唯一原因，其举出了相同train-test accuracy gap的情况下，Google的攻击效果更好来说明。</p>
<p>个人认为有一定道理，可能某些算法或网络结构，会导致其过拟合时，训练集、测试集输出的概率分布特征差别比其他算法大。</p>
<p>不过这并不能掩盖过拟合是导致攻击成功的重要因素这一事实。</p>
<h3 id="防御"><a href="#防御" class="headerlink" title="防御"></a>防御</h3><p>作者给出了一些方法来防御，大体是两个思路：</p>
<ul>
<li>减少攻击者可知的信息：目标模型不直接返回$\hat{y}$，而是top-k的$\hat{y}$，或者干脆只返回类别标签。</li>
<li>减轻过拟合：谷歌等云服务平台，有必要提醒用户过拟合的安全风险，并设法避免过拟合。</li>
</ul>
<h2 id="评价"><a href="#评价" class="headerlink" title="评价"></a>评价</h2><ul>
<li>看起来，文章证明了：对于训练集和测试集，模型输出的$\hat{y}$具有不同的特征。实际上，前提基本是过拟合。</li>
<li>原以为比较理论，实际上比较工程的工作</li>
<li>实际上，个人感觉攻击场景比较受限，实际意义不大</li>
<li>数据获取场景，感觉也就Model-based synthesis和Statistics-based synthesis比较实际</li>
<li>作者使用的数据集是低分辨率的CIFAR，以及一些结构性的数据。如果数据本身复杂度高，那么攻击成本就比较大。例如，如果是高分辨率图像，那么实际场景中，要生成这些数据，就比较难</li>
</ul>

      
    </div>
    <footer class="article-footer">
	  
	  <!-- 百度分享 Start -->
	  <div class="bdsharebuttonbox"><a href="#" class="bds_more" data-cmd="more"></a><a href="#" class="bds_qzone" data-cmd="qzone" title="分享到QQ空间"></a><a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a><a href="#" class="bds_tqq" data-cmd="tqq" title="分享到腾讯微博"></a><a href="#" class="bds_renren" data-cmd="renren" title="分享到人人网"></a><a href="#" class="bds_weixin" data-cmd="weixin" title="分享到微信"></a></div>
	  <!-- 百度分享 End -->
    
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%BF%87%E6%8B%9F%E5%90%88/" rel="tag">过拟合</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4/" rel="tag">隐私保护</a></li></ul>

	  

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2021/12/16/paper_notes/xmcgan/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          论文笔记：Cross-Modal Contrastive Learning for Text-to-Image Generation, CVPR 2021
        
      </div>
    </a>
  
  
    <a href="/2021/12/05/paper_notes/dlg/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">论文笔记：Deep Leakage from Gradients, NeurIPS 2019</div>
    </a>
  
</nav>

  
</article>



  <section id="comments" class="vcomment">

  </section>
</section>
        
          
  <div id="toc" class="toc-aside">
  <h2 class="toc-title">Contents</h2>
    
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%95%E8%A8%80"><span class="toc-number">1.</span> <span class="toc-text">引言</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%97%AE%E9%A2%98%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">1.1.</span> <span class="toc-text">问题是什么？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AF%E8%BF%99%E4%B8%AA%E9%97%AE%E9%A2%98%EF%BC%9F"><span class="toc-number">1.2.</span> <span class="toc-text">为什么是这个问题？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%BA%E6%96%87%E7%9A%84Overview"><span class="toc-number">1.3.</span> <span class="toc-text">论文的Overview</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%B9%E6%B3%95"><span class="toc-number">2.</span> <span class="toc-text">方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%B9%E6%B3%95%E6%80%9D%E8%B7%AF"><span class="toc-number">2.1.</span> <span class="toc-text">方法思路</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E6%9D%A5%E6%BA%90"><span class="toc-number">2.2.</span> <span class="toc-text">数据集来源</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BD%B1%E5%AD%90%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%92%8C%E4%B8%AA%E6%95%B0"><span class="toc-number">2.3.</span> <span class="toc-text">影子模型的设计和个数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E6%94%BB%E5%87%BB%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.4.</span> <span class="toc-text">训练攻击模型</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E6%9E%9C"><span class="toc-number">3.</span> <span class="toc-text">结果</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%A8%E8%AE%BA"><span class="toc-number">4.</span> <span class="toc-text">讨论</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%87%E6%8B%9F%E5%90%88%E8%B6%8A%E4%B8%A5%E9%87%8D%EF%BC%8C%E6%94%BB%E5%87%BB%E6%95%88%E6%9E%9C%E8%B6%8A%E5%A5%BD"><span class="toc-number">4.1.</span> <span class="toc-text">过拟合越严重，攻击效果越好</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%98%B2%E5%BE%A1"><span class="toc-number">4.2.</span> <span class="toc-text">防御</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%84%E4%BB%B7"><span class="toc-number">5.</span> <span class="toc-text">评价</span></a></li></ol>
    
  </div>

<aside id="sidebar">

  
    
<div class="widget-wrap">
  <h3 class="widget-title">ABOUT ME</h3>
  <ul class="widget about-me">
    
    <li><img class="author" title="About me" src="/images/coffee_onetwo.jpg" /></li>
    
    
    <li>Hi, LuYongjian! LYJNB!</li>
    
  </ul>
</div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E9%9A%8F%E7%AC%94/">随笔</a><span class="category-list-count">9</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/CTC/" style="font-size: 13px; color: #7dc3de">CTC</a> <a href="/tags/GAN/" style="font-size: 14.17px; color: #6dc1b9">GAN</a> <a href="/tags/PyTorch/" style="font-size: 13px; color: #7dc3de">PyTorch</a> <a href="/tags/RTX-4090/" style="font-size: 13px; color: #7dc3de">RTX 4090</a> <a href="/tags/ReLU/" style="font-size: 14.17px; color: #6dc1b9">ReLU</a> <a href="/tags/Text-to-Image/" style="font-size: 13px; color: #7dc3de">Text-to-Image</a> <a href="/tags/Windows%E7%BC%96%E7%A8%8B/" style="font-size: 13px; color: #7dc3de">Windows编程</a> <a href="/tags/copyright/" style="font-size: 13px; color: #7dc3de">copyright</a> <a href="/tags/nvidia/" style="font-size: 13px; color: #7dc3de">nvidia</a> <a href="/tags/tensorflow-1-15/" style="font-size: 13px; color: #7dc3de">tensorflow 1.15</a> <a href="/tags/viterbi%E7%AE%97%E6%B3%95/" style="font-size: 13px; color: #7dc3de">viterbi算法</a> <a href="/tags/%E4%B8%AD%E5%BF%83%E5%8C%96%E5%B7%AE%E5%88%86%E9%9A%90%E7%A7%81/" style="font-size: 13px; color: #7dc3de">中心化差分隐私</a> <a href="/tags/%E4%BA%8C%E5%80%BC%E5%8C%96/" style="font-size: 13px; color: #7dc3de">二值化</a> <a href="/tags/%E4%BB%A3%E7%A0%81%E6%B3%A8%E5%85%A5/" style="font-size: 13px; color: #7dc3de">代码注入</a> <a href="/tags/%E4%BD%8E%E9%80%9A%E6%BB%A4%E6%B3%A2/" style="font-size: 13px; color: #7dc3de">低通滤波</a> <a href="/tags/%E4%BD%8E%E9%80%9A%E6%BB%A4%E6%B3%A2%E5%99%A8/" style="font-size: 13px; color: #7dc3de">低通滤波器</a> <a href="/tags/%E5%86%85%E5%AD%98%E6%B3%84%E9%9C%B2/" style="font-size: 13px; color: #7dc3de">内存泄露</a> <a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%A6%E4%B9%A0/" style="font-size: 13px; color: #7dc3de">分布式学习</a> <a href="/tags/%E5%89%8D%E5%90%91%E7%AE%97%E6%B3%95/" style="font-size: 13px; color: #7dc3de">前向算法</a> <a href="/tags/%E5%8D%8F%E4%BD%9C%E5%AD%A6%E4%B9%A0/" style="font-size: 13px; color: #7dc3de">协作学习</a> <a href="/tags/%E5%8F%8C%E7%BA%BF%E6%80%A7%E6%8F%92%E5%80%BC/" style="font-size: 13px; color: #7dc3de">双线性插值</a> <a href="/tags/%E5%8F%AF%E8%A7%86%E5%8C%96/" style="font-size: 16.5px; color: #4dbc6f">可视化</a> <a href="/tags/%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/" style="font-size: 17.67px; color: #3db94a">可解释性</a> <a href="/tags/%E5%90%8E%E9%97%A8%E6%94%BB%E5%87%BB/" style="font-size: 13px; color: #7dc3de">后门攻击</a> <a href="/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/" style="font-size: 13px; color: #7dc3de">图像分割</a> <a href="/tags/%E5%9B%BE%E7%89%87%E8%AF%86%E5%88%AB/" style="font-size: 13px; color: #7dc3de">图片识别</a> <a href="/tags/%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB/" style="font-size: 16.5px; color: #4dbc6f">对抗攻击</a> <a href="/tags/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC/" style="font-size: 14.17px; color: #6dc1b9">对抗样本</a> <a href="/tags/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/" style="font-size: 13px; color: #7dc3de">对比学习</a> <a href="/tags/%E5%B7%AE%E5%88%86%E9%9A%90%E7%A7%81/" style="font-size: 13px; color: #7dc3de">差分隐私</a> <a href="/tags/%E6%94%BF%E6%B2%BB%E7%BB%8F%E6%B5%8E%E5%AD%A6%E6%A6%82%E8%AE%BA/" style="font-size: 13px; color: #7dc3de">政治经济学概论</a> <a href="/tags/%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/" style="font-size: 14.17px; color: #6dc1b9">数字信号处理</a> <a href="/tags/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/" style="font-size: 14.17px; color: #6dc1b9">数字图像处理</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E6%8A%95%E6%AF%92/" style="font-size: 13px; color: #7dc3de">数据投毒</a> <a href="/tags/%E6%9C%AC%E5%9C%B0%E5%8C%96%E5%B7%AE%E5%88%86%E9%9A%90%E7%A7%81/" style="font-size: 13px; color: #7dc3de">本地化差分隐私</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 14.17px; color: #6dc1b9">机器学习</a> <a href="/tags/%E6%A8%A1%E5%9E%8B%E9%B2%81%E6%A3%92%E6%80%A7/" style="font-size: 13px; color: #7dc3de">模型鲁棒性</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 20px; color: #1db400">深度学习</a> <a href="/tags/%E7%89%88%E6%9D%83%E4%BF%9D%E6%8A%A4/" style="font-size: 13px; color: #7dc3de">版权保护</a> <a href="/tags/%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/" style="font-size: 13px; color: #7dc3de">生成对抗网络</a> <a href="/tags/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/" style="font-size: 13px; color: #7dc3de">生成模型</a> <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" style="font-size: 18.83px; color: #2db725">神经网络</a> <a href="/tags/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 13px; color: #7dc3de">联邦学习</a> <a href="/tags/%E8%A7%86%E9%A2%91/" style="font-size: 13px; color: #7dc3de">视频</a> <a href="/tags/%E8%B7%A8%E6%A8%A1%E6%80%81/" style="font-size: 13px; color: #7dc3de">跨模态</a> <a href="/tags/%E8%BF%87%E6%8B%9F%E5%90%88/" style="font-size: 13px; color: #7dc3de">过拟合</a> <a href="/tags/%E9%87%8D%E9%87%87%E6%A0%B7/" style="font-size: 13px; color: #7dc3de">重采样</a> <a href="/tags/%E9%87%8D%E9%87%87%E6%A0%B7%E7%AE%97%E6%B3%95/" style="font-size: 13px; color: #7dc3de">重采样算法</a> <a href="/tags/%E9%98%88%E5%80%BC%E5%A4%84%E7%90%86/" style="font-size: 13px; color: #7dc3de">阈值处理</a> <a href="/tags/%E9%99%8D%E9%87%87%E6%A0%B7/" style="font-size: 13px; color: #7dc3de">降采样</a> <a href="/tags/%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4/" style="font-size: 15.33px; color: #5dbe94">隐私保护</a> <a href="/tags/%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB/" style="font-size: 13px; color: #7dc3de">隐马尔可夫</a> <a href="/tags/%E9%9F%B3%E9%A2%91%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB/" style="font-size: 14.17px; color: #6dc1b9">音频对抗攻击</a> <a href="/tags/%E9%9F%B3%E9%A2%91%E9%A2%84%E5%A4%84%E7%90%86/" style="font-size: 13px; color: #7dc3de">音频预处理</a> <a href="/tags/%E9%A2%91%E8%B0%B1%E6%B7%B7%E5%8F%A0/" style="font-size: 13px; color: #7dc3de">频谱混叠</a> <a href="/tags/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB/" style="font-size: 13px; color: #7dc3de">马尔可夫</a>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/02/">February 2023</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/01/">January 2023</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/10/">October 2022</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/03/">March 2022</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/12/">December 2021</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/11/">November 2021</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/09/">September 2021</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/06/">June 2021</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/05/">May 2021</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/03/">March 2021</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/01/">January 2021</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/12/">December 2020</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/11/">November 2020</a><span class="archive-list-count">3</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2023/02/17/suibi/image_lowpass_filtering/">Image Low-pass Filtering Algorithms Ideal/Butterworth/Gaussian (PyTorch Implementation) 图像低通滤波算法PyTorch实现</a>
          </li>
        
          <li>
            <a href="/2023/01/09/suibi/nv_tf1155_bug/">nvidia-tensorflow 1.15.5的signal模块的一个内存泄漏bug</a>
          </li>
        
          <li>
            <a href="/2022/10/18/paper_notes/cvpr20_video_backdoor/">CVPR2020 Clean-Label Backdoor Attacks on Video Recognition Models</a>
          </li>
        
          <li>
            <a href="/2022/03/31/suibi/code_inject/">代码注入：调用CreateProcess使explorer启动目标进程</a>
          </li>
        
          <li>
            <a href="/2021/12/16/paper_notes/xmcgan/">论文笔记：Cross-Modal Contrastive Learning for Text-to-Image Generation, CVPR 2021</a>
          </li>
        
      </ul>
    </div>
  </div>


  
    
<div class="widget-wrap">
  <h3 class="widget-title">Links</h3>
  <ul class="widget">
    
    <li><a href="https://qgrain.github.io/" target="_BLANK">Zhiyu&#39;s Blog</a></li>
    
    <li><a href="https://github.com/CassiniHuy" target="_BLANK">CassiniHuy&#39;s Github</a></li>
    
    <li><a href="https://www.marxists.org/chinese/marx/index.htm" target="_BLANK">中文马克思主义文库</a></li>
    
    <li><a href="https://www.zdic.net/" target="_BLANK">汉典</a></li>
    
  </ul>
</div>


  

</aside>

        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 cassiniwei@outlook.com<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> and Theme by <a href="https://github.com/howiefh/hexo-theme-landscape-f" target="_blank" title="Landscape-F">Landscape-F</a>
    
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<!-- 百度分享 start -->
<script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":["mshare","douban","bdysc","sqq","qq","hi","baidu","huaban","youdao","sdo","mail","xg","diandian","fx","copy","print"],"bdPic":"","bdStyle":"1","bdSize":"16"},"share":{},"image":{"viewList":["qzone","tsina","tqq","renren","weixin"],"viewText":"分享到","viewSize":"16"}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];</script>
<!-- 百度分享 end -->



<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>



<div class="bottom-btn">

	<a class="icon-gotop" href="javascript:void(0)" title="返回顶部"></a>
	
<script src="/js/gotop.js"></script>



	<a class="icon-toc-toggle" href="javascript:void(0)" title="文章目录"></a>
	
<script src="/js/toc_aside_toggle.js"></script>


</div>



<script src="/js/script.js"></script>









  
<script src="https://cdn.jsdelivr.net/npm/valine@1.3.10/dist/Valine.min.js"></script>

<script>
    var GUEST_INFO = ['nick','mail','link'];
    var guest_info = 'nick,mail,link'.split(',').filter(function(item){
        return GUEST_INFO.indexOf(item) > -1
    });
    var notify = 'true' == true;
    var verify = 'true' == true;
    new Valine({
        el: '.vcomment',
        notify: notify,
        verify: verify,
        appId: "sA5b5bSKVOumVxcKtX8NUqFk-gzGzoHsz",
        appKey: "glFUguQG84y2GTeKhQR0RNAX",
        placeholder: "Feel free to comment but new comment notification is disabled. Please contact me by cassiniwei@outlook.com if needed.",
        pageSize:'10',
        avatar:'mm',
        lang:''
    });
</script>


  </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<!-- <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->
<script src="//cdn.bootcss.com/mathjax/2.7.3/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</body>
</html>
